---

title: Action Recognition


keywords: fastai
sidebar: home_sidebar

summary: "Implementation of various architectures to solve the UCF 101 actions dataset"
description: "Implementation of various architectures to solve the UCF 101 actions dataset"
nb_path: "nbs/index.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/index.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It is based on the implementations found on <a href="https://github.com/eriklindernoren/Action-Recognition">Action Recognition</a>.</p>
<p>I try to keep with updated architectures that come out. Right now transformers are all we need... Follow @lucidrains to get the next attention based model ASAP.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Install">Install<a class="anchor-link" href="#Install"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>First install <code>fastai</code>:</p>
<div class="highlight"><pre><span></span>$ pip install fastcore fastai
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Results">Results<a class="anchor-link" href="#Results"> </a></h2><p>Results are computed on a random splut 80%/20%. Using <code>fastai2</code> built-in <code>fit_one_cycle</code> training.</p>
<ul>
<li><a href="01_train_baseline.ipynb">train baseline</a>: Implements a Basic Resnet 34 encoder coupled with a simple attention layer over the frames. (91% accuracy)</li>
<li><a href="02_train_convlstm.ipynb">train convlstm</a>: resnet34 encoder + LSTM layer over image features. (84.8% accuracy)</li>
<li><a href="03_train_transformer.ipynb">train_transformer</a>: Added the new TimeSformer and STAM from @lucidrains implementations.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This package also provides function to download nad process the video dataset into multiple frames.</p>

</div>
</div>
</div>
</div>
 

